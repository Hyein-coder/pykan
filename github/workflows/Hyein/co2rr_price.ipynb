{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T07:23:24.812362Z",
     "start_time": "2025-11-04T07:23:21.995839Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from kan.custom_processing import (plot_data_per_interval,\n",
    "                                   plot_activation_and_spline_coefficients, get_masks)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['savefig.dpi'] = 75*10\n",
    "\n",
    "root_dir = os.path.join(os.getcwd())\n",
    "save_dir = os.path.join(root_dir, \"custom_figures\")\n",
    "time_stamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "fn = \"CO2RR_MSP_20251104_1025\"\n",
    "save_tag = fn + \"_analysis\"\n",
    "save_heading = os.path.join(save_dir, save_tag)\n",
    "\n",
    "df = pd.read_excel(os.path.join(root_dir, 'multkan_sweep_autosave', fn + \".xlsx\"), sheet_name='best_avg_by_params')\n",
    "d_opt = df\n",
    "\n",
    "d_opt_flat = d_opt.iloc[0]\n",
    "d_opt_flat = d_opt_flat.to_dict()\n",
    "params = {k: v for k, v in d_opt_flat.items() if \"param_\" in k}\n",
    "params = {key.replace('param_', ''): value for key, value in params.items()}"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:24:55.722599Z",
     "start_time": "2025-11-04T07:24:55.346592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kan.custom_processing import remove_outliers_iqr\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"This script is running on {device}.\")\n",
    "\n",
    "filepath = os.path.join(\"..\\TaeWoong\", \"25.01.14_CO2RR_GSA.xlsx\")\n",
    "\n",
    "xls = pd.ExcelFile(filepath)\n",
    "df_in = pd.read_excel(xls, sheet_name='Input')\n",
    "df_out = pd.read_excel(xls, sheet_name='Output')\n",
    "\n",
    "df_in_final, df_out_final = remove_outliers_iqr(df_in, df_out)\n",
    "\n",
    "removed_count = len(df_in) - len(df_in_final)  # 몇 개 지웠는지 세기\n",
    "print(f\"이상치 제거 후 데이터 수: {len(df_in_final)} 개 ({removed_count} 개 제거됨)\")\n",
    "print(\"--- 이상치 제거 완료 ---\\n\")\n",
    "\n",
    "name_X = [\n",
    "    \"Current density (mA/cm2)\",\n",
    "    \"Faradaic efficiency (%)\",\n",
    "    \"CO coversion\",\n",
    "    \"Voltage (V)\",\n",
    "    \"Electricity cost ($/kWh)\",\n",
    "    \"Membrain cost ($/m2)\",\n",
    "    \"Catpure energy (GJ/ton)\",\n",
    "    \"Crossover rate\"\n",
    "]\n",
    "name_y = \"MSP ($/kgCO)\"  # Required energy_total (MJ/kgCO) # MSP ($/kgCO)\n",
    "X = df_in_final[name_X].values\n",
    "y = df_out_final[name_y].values.reshape(-1, 1)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2,\n",
    "                                                  random_state=42)  # 0.2 × 0.8 = 0.16 (전체의 16%)\n",
    "\n",
    "print(f\"전체 데이터셋 크기: {len(X)}\")\n",
    "print(f\"훈련셋 크기: {len(X_train)} ({len(X_train) / len(X) * 100:.1f}%)\")\n",
    "print(f\"검증셋 크기: {len(X_val)} ({len(X_val) / len(X) * 100:.1f}%)\")\n",
    "print(f\"테스트셋 크기: {len(X_test)} ({len(X_test) / len(X) * 100:.1f}%)\")\n",
    "\n",
    "# 1. MinMaxScaler 객체 생성 --- 범위를 0.1~0.9로 재설정\n",
    "scaler_X = MinMaxScaler(feature_range=(0.1, 0.9))\n",
    "scaler_y = MinMaxScaler(feature_range=(0.1, 0.9))\n",
    "\n",
    "X_train_norm = scaler_X.fit_transform(X_train)  # 훈련 데이터로 스케일러 학습 및 변환 (fit_transform)\n",
    "y_train_norm = scaler_y.fit_transform(y_train)  # X_train의 각 변수(컬럼)별로 최소값은 0, 최대값은 1이 되도록 변환됩니다.\n",
    "\n",
    "X_val_norm = scaler_X.transform(X_val)\n",
    "X_test_norm = scaler_X.transform(X_test)\n",
    "\n",
    "y_val_norm = scaler_y.transform(y_val)\n",
    "y_test_norm = scaler_y.transform(y_test)"
   ],
   "id": "fec9d67bb9f852c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script is running on cpu.\n",
      "이상치 제거 후 데이터 수: 2378 개 (123 개 제거됨)\n",
      "--- 이상치 제거 완료 ---\n",
      "\n",
      "전체 데이터셋 크기: 2378\n",
      "훈련셋 크기: 1521 (64.0%)\n",
      "검증셋 크기: 381 (16.0%)\n",
      "테스트셋 크기: 476 (20.0%)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script is running on cpu.\n",
      "이상치 제거 후 데이터 수: 2378 개 (123 개 제거됨)\n",
      "--- 이상치 제거 완료 ---\n",
      "\n",
      "전체 데이터셋 크기: 2378\n",
      "훈련셋 크기: 1521 (64.0%)\n",
      "검증셋 크기: 381 (16.0%)\n",
      "테스트셋 크기: 476 (20.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 2.86e-03 | test_loss: 3.18e-03 | reg: 3.28e+00 | : 100%|█| 50/50 [00:24<00:00,  2.01it\n",
      "| train_loss: 2.23e-03 | test_loss: 2.42e-03 | reg: 2.80e+00 | : 100%|█| 50/50 [00:24<00:00,  2.04it\n",
      "description:   0%|                                                           | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 58\u001B[0m\n\u001B[0;32m     55\u001B[0m y_val_norm \u001B[38;5;241m=\u001B[39m scaler_y\u001B[38;5;241m.\u001B[39mtransform(y_val)\n\u001B[0;32m     56\u001B[0m y_test_norm \u001B[38;5;241m=\u001B[39m scaler_y\u001B[38;5;241m.\u001B[39mtransform(y_test)\n\u001B[1;32m---> 58\u001B[0m res, model, fit_kwargs, dataset \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_params\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_heading\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_heading\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m model\u001B[38;5;241m.\u001B[39mplot()\n\u001B[0;32m     64\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32mD:\\pykan\\kan\\experiments\\multkan_hparam_sweep.py:617\u001B[0m, in \u001B[0;36mevaluate_params\u001B[1;34m(X_train, y_train, X_val, y_val, params, X_test, y_test, seed, scaler_y, device_str, save_heading)\u001B[0m\n\u001B[0;32m    614\u001B[0m     save_heading \u001B[38;5;241m=\u001B[39m auto_save_path\n\u001B[0;32m    615\u001B[0m fig_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_heading\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_eval.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 617\u001B[0m res, model, fit_kwargs, dataset \u001B[38;5;241m=\u001B[39m \u001B[43m_run_single_trial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    619\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(device_str)\n\u001B[0;32m    620\u001B[0m y_true, y_pred, mae, r2 \u001B[38;5;241m=\u001B[39m mae_and_r2(model, _to_tensor(X_val, device), _to_tensor(y_val, device), scaler_y\u001B[38;5;241m=\u001B[39mscaler_y)\n",
      "File \u001B[1;32mD:\\pykan\\kan\\experiments\\multkan_hparam_sweep.py:179\u001B[0m, in \u001B[0;36m_run_single_trial\u001B[1;34m(args, verbose)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m grid \u001B[38;5;129;01min\u001B[39;00m refine_grid:\n\u001B[0;32m    178\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mrefine(grid)\n\u001B[1;32m--> 179\u001B[0m     res_spline \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(dataset, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs)\n\u001B[0;32m    180\u001B[0m     refine_res\u001B[38;5;241m.\u001B[39mappend(res_spline)\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _want_prune(params):\n\u001B[0;32m    183\u001B[0m         \u001B[38;5;66;03m# Unified pruning threshold handling: if 'pruning_th' is provided, use it for both node_th and edge_th\u001B[39;00m\n",
      "File \u001B[1;32mD:\\pykan\\kan\\custom_multkan_ddp.py:444\u001B[0m, in \u001B[0;36mMultKAN.fit\u001B[1;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, singularity_avoiding, y_th, reg_metric, display_metrics, monitor, log_history, shuffle, eval_test_loss)\u001B[0m\n\u001B[0;32m    442\u001B[0m         scheduler\u001B[38;5;241m.\u001B[39mstep(loss)\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m opt \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLBFGS\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 444\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eval_test_loss:  \u001B[38;5;66;03m# added\u001B[39;00m\n\u001B[0;32m    447\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m loss_fn_eval(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_input\u001B[39m\u001B[38;5;124m'\u001B[39m][test_id]), dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_label\u001B[39m\u001B[38;5;124m'\u001B[39m][test_id])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\pykan-new\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m             )\n\u001B[1;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\pykan-new\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\pykan\\kan\\LBFGS.py:443\u001B[0m, in \u001B[0;36mLBFGS.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    441\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mobj_func\u001B[39m(x, t, d):\n\u001B[0;32m    442\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_directional_evaluate(closure, x, t, d)\n\u001B[1;32m--> 443\u001B[0m     loss, flat_grad, t, ls_func_evals \u001B[38;5;241m=\u001B[39m \u001B[43m_strong_wolfe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_grad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgtd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_grad(t, d)\n\u001B[0;32m    446\u001B[0m opt_cond \u001B[38;5;241m=\u001B[39m flat_grad\u001B[38;5;241m.\u001B[39mabs()\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m tolerance_grad\n",
      "File \u001B[1;32mD:\\pykan\\kan\\LBFGS.py:50\u001B[0m, in \u001B[0;36m_strong_wolfe\u001B[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001B[0m\n\u001B[0;32m     48\u001B[0m g \u001B[38;5;241m=\u001B[39m g\u001B[38;5;241m.\u001B[39mclone(memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcontiguous_format)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# evaluate objective and gradient using initial step\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m f_new, g_new \u001B[38;5;241m=\u001B[39m \u001B[43mobj_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m ls_func_evals \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     52\u001B[0m gtd_new \u001B[38;5;241m=\u001B[39m g_new\u001B[38;5;241m.\u001B[39mdot(d)\n",
      "File \u001B[1;32mD:\\pykan\\kan\\LBFGS.py:442\u001B[0m, in \u001B[0;36mLBFGS.step.<locals>.obj_func\u001B[1;34m(x, t, d)\u001B[0m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mobj_func\u001B[39m(x, t, d):\n\u001B[1;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_directional_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\pykan\\kan\\LBFGS.py:291\u001B[0m, in \u001B[0;36mLBFGS._directional_evaluate\u001B[1;34m(self, closure, x, t, d)\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_directional_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure, x, t, d):\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_grad(t, d)\n\u001B[1;32m--> 291\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    292\u001B[0m     flat_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gather_flat_grad()\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_param(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\pykan-new\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\pykan\\kan\\custom_multkan_ddp.py:389\u001B[0m, in \u001B[0;36mMultKAN.fit.<locals>.closure\u001B[1;34m()\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m train_loss, reg_\n\u001B[0;32m    388\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 389\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msingularity_avoiding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingularity_avoiding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_th\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_th\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_label\u001B[39m\u001B[38;5;124m'\u001B[39m][train_id])\n\u001B[0;32m    391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_act:\n",
      "File \u001B[1;32mD:\\pykan\\kan\\custom_multkan_ddp.py:141\u001B[0m, in \u001B[0;36mMultKAN.forward\u001B[1;34m(self, x, singularity_avoiding, y_th)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# print(preacts, postacts_numerical, postspline)\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misnan(x_numerical)\u001B[38;5;241m.\u001B[39many():  \u001B[38;5;66;03m# added checker\u001B[39;00m\n\u001B[1;32m--> 141\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misnan(preacts)\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: No active exception to reraise"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "from kan.experiments.multkan_hparam_sweep import evaluate_params\n",
    "\n",
    "res, model, fit_kwargs, dataset = evaluate_params(\n",
    "    X_train_norm, y_train_norm, X_val_norm, y_val_norm, params, X_test_norm, y_test_norm,\n",
    "    0, scaler_y, device.type,\n",
    "    save_heading=save_heading\n",
    ")\n",
    "model.plot()\n",
    "plt.show()"
   ],
   "id": "4b54ccb415f028ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from kan.custom_processing import plot_data_per_interval\n",
    "X_norm = scaler_X.transform(X)\n",
    "y_norm = scaler_y.transform(y)\n",
    "# X_norm_selected = X_norm[:, [1, 2, 3, 6]]\n",
    "\n",
    "# fig_x2, axs_x2 = plot_data_per_interval(X_norm, y_norm, name_X, name_y, 2, [0, 0.3, 0.6])\n",
    "fig_x2, axs_x2 = plot_data_per_interval(X_norm, y_norm, name_X, name_y, 2, [0, 0.2, 0.4])\n",
    "\n",
    "plot_activation_and_spline_coefficients(model, save_heading=save_heading, x=dataset, layers=None)"
   ],
   "id": "6228e1b7a9ad8958"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
